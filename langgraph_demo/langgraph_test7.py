import operator
import uuid
from typing import Annotated, List, Literal, TypedDict, Union

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage, RemoveMessage, trim_messages
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig

from langgraph.graph import StateGraph, END, START, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.memory import InMemoryStore # å¼•å…¥å­˜å‚¨

# --- 1. å®šä¹‰å·¥å…· ---

@tool
def search_flights(destination: str):
    """æŸ¥è¯¢èˆªç­"""
    return f"æŸ¥è¯¢ç»“æœ: å»å¾€ {destination} çš„èˆªç­æœ‰ CA123 (Â¥1000)ã€‚"

@tool
def book_ticket(flight_no: str):
    """é¢„è®¢èˆªç­"""
    return f"é¢„è®¢æˆåŠŸ: {flight_no}"

tools = [search_flights, book_ticket]

# --- 2. åˆå§‹åŒ–æ¨¡å‹ ---

llm = ChatOpenAI(model="Qwen3-30B-A3B", base_url="http://192.168.0.147:8997/v1", api_key="123456",temperature=0)
llm_with_tools = llm.bind_tools(tools)

# --- 3. æ ¸å¿ƒé€»è¾‘ï¼šç»“åˆ Store çš„èŠå¤©èŠ‚ç‚¹ ---

def call_model(state: MessagesState, config: RunnableConfig, store: InMemoryStore):
    """
    ä¸»å¯¹è¯èŠ‚ç‚¹ï¼š
    1. ä» Store ä¸­æå–é•¿æœŸè®°å¿†ï¼ˆæ‘˜è¦ + ç”¨æˆ·ç”»åƒï¼‰ã€‚
    2. å°†é•¿æœŸè®°å¿†æ³¨å…¥ System Promptã€‚
    3. ç»“åˆçŸ­æœŸè®°å¿†ï¼ˆstate['messages']ï¼‰è¿›è¡Œå›ç­”ã€‚
    """
    user_id = config["configurable"]["thread_id"]
    
    # --- A. ä» Store è·å–è®°å¿† ---
    # æˆ‘ä»¬ä½¿ç”¨ (namespace, key) æ¥å®šä½æ•°æ®
    # namespace é€šå¸¸ç”¨äºéš”ç¦»ä¸åŒç±»å‹çš„æ•°æ®ï¼Œkey æ˜¯ç”¨æˆ·ID
    namespace = ("user_memory",) 
    memory_data = store.get(namespace, user_id)
    
    summary = ""
    if memory_data:
        summary = memory_data.value.get("summary", "")
        
    # --- B. æ„å»º Prompt ---
    system_msg = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚
    
    ã€é•¿æœŸè®°å¿†/å·²çŸ¥ä¿¡æ¯ã€‘
    {summary if summary else "æš‚æ— ä¹‹å‰çš„è®°å¿†ã€‚"}
    
    ã€å½“å‰ä»»åŠ¡ã€‘
    è¯·æ ¹æ®ä¸Šè¿°è®°å¿†å’Œä¸‹æ–¹çš„æœ€æ–°å¯¹è¯å›å¤ç”¨æˆ·ã€‚
    """
    
    # ç¡®ä¿ SystemMessage å§‹ç»ˆåœ¨æœ€å‰
    messages = [SystemMessage(content=system_msg)] + state["messages"]
    
    # è°ƒç”¨æ¨¡å‹
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}

# --- 4. æ ¸å¿ƒé€»è¾‘ï¼šæ€»ç»“ä¸ä¿®å‰ªèŠ‚ç‚¹ ---

def summarize_conversation(state: MessagesState, config: RunnableConfig, store: InMemoryStore):
    """
    æ€»ç»“èŠ‚ç‚¹ï¼š
    1. è¯»å–å½“å‰æ‰€æœ‰æ¶ˆæ¯ã€‚
    2. ç”Ÿæˆæ–°çš„æ‘˜è¦ã€‚
    3. å°†æ‘˜è¦å­˜å…¥ Storeã€‚
    4. åˆ é™¤æ—§æ¶ˆæ¯ï¼ˆé‡Šæ”¾ Tokenï¼‰ã€‚
    """
    user_id = config["configurable"]["thread_id"]
    namespace = ("user_memory",)
    
    # 1. è·å–æ—§æ‘˜è¦
    existing_data = store.get(namespace, user_id)
    existing_summary = existing_data.value.get("summary", "") if existing_data else ""
    
    messages = state["messages"]
    
    # å¦‚æœæ¶ˆæ¯å¤ªå°‘ï¼Œå°±ä¸æ€»ç»“äº†ï¼ˆé˜²æ­¢é¢‘ç¹è°ƒç”¨æµªè´¹é’±ï¼‰
    if len(messages) < 6:
        return {}

    # 2. è°ƒç”¨ LLM ç”Ÿæˆæ–°æ‘˜è¦
    # æˆ‘ä»¬æŠŠæ—§æ‘˜è¦ + å½“å‰å¯¹è¯å‘ç»™ LLMï¼Œè®©å®ƒåˆå¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„
    prompt = f"""è¯·å°†å½“å‰çš„å¯¹è¯å†…å®¹åˆå¹¶åˆ°ç°æœ‰çš„è®°å¿†æ‘˜è¦ä¸­ã€‚
    ä¿ç•™å…³é”®ä¿¡æ¯ï¼ˆå¦‚ç”¨æˆ·çš„åå­—ã€ç›®çš„åœ°ã€åå¥½ã€å·²å®Œæˆçš„è®¢å•ï¼‰ã€‚
    
    ã€ç°æœ‰æ‘˜è¦ã€‘
    {existing_summary}
    
    ã€æ–°å¢å¯¹è¯ã€‘
    {messages}
    
    è¯·è¾“å‡ºæ–°çš„æ‘˜è¦ï¼š
    """
    response = llm.invoke([HumanMessage(content=prompt)])
    new_summary = response.content
    
    # 3. å­˜å…¥ Store (æŒä¹…åŒ–)
    store.put(namespace, user_id, {"summary": new_summary})
    print(f"\nğŸ’¾ [ç³»ç»Ÿ] å·²æ›´æ–°é•¿æœŸè®°å¿†: {new_summary[:50]}...")
    
    # 4. åˆ é™¤æ—§æ¶ˆæ¯ (ä¿®å‰ª)
    # æˆ‘ä»¬ä¿ç•™æœ€å 2 æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ User query å’Œå½“å‰çš„ AI responseï¼‰ï¼Œåˆ é™¤ä¹‹å‰çš„
    # RemoveMessage æ˜¯ LangGraph ç‰¹æœ‰çš„æœºåˆ¶ï¼Œç”¨äºä» State ä¸­ç‰©ç†åˆ é™¤æ¶ˆæ¯
    delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]
    
    return {"messages": delete_messages}

# --- 5. å®šä¹‰æ¡ä»¶é€»è¾‘ï¼šä½•æ—¶è§¦å‘æ€»ç»“ï¼Ÿ ---

def should_summarize(state: MessagesState):
    """
    å†³å®šä¸‹ä¸€æ­¥å»å“ªï¼š
    1. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ -> tools
    2. å¦‚æœæ¶ˆæ¯åˆ—è¡¨å¤ªé•¿ï¼ˆæ¯”å¦‚è¶…è¿‡ 6 æ¡ï¼‰ -> summarize_conversation
    3. å¦åˆ™ -> END (ç­‰å¾…ç”¨æˆ·è¾“å…¥)
    """
    messages = state["messages"]
    last_message = messages[-1]
    
    # ä¼˜å…ˆå¤„ç†å·¥å…·è°ƒç”¨
    if last_message.tool_calls:
        return "tools"
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“ï¼ˆè¿™é‡Œè®¾å®šé˜ˆå€¼ä¸º 6 æ¡æ¶ˆæ¯ï¼‰
    # æ³¨æ„ï¼šå®é™…ç”Ÿäº§ä¸­å¯ä»¥ä½¿ç”¨ token è®¡æ•°å™¨æ¥åˆ¤æ–­
    if len(messages) > 6:
        return "summarize_conversation"
    
    return END

# --- 6. æ„å»ºå›¾ ---

workflow = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("chatbot", call_model)
workflow.add_node("tools", ToolNode(tools))
workflow.add_node("summarize_conversation", summarize_conversation)

# è®¾ç½®å…¥å£
workflow.add_edge(START, "chatbot")

# è®¾ç½®å¤æ‚çš„æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "chatbot",
    should_summarize,
    {
        "tools": "tools",
        "summarize_conversation": "summarize_conversation",
        END: END
    }
)

# å·¥å…·æ‰§è¡Œå®Œå› chatbot
workflow.add_edge("tools", "chatbot")

# æ€»ç»“æ‰§è¡Œå®Œç»“æŸï¼ˆç­‰å¾…ç”¨æˆ·ä¸‹ä¸€è½®ï¼‰
workflow.add_edge("summarize_conversation", END)

# --- 7. ç¼–è¯‘ ---

# æ—¢éœ€è¦ Checkpointer (çŸ­æœŸä¼šè¯çŠ¶æ€)ï¼Œä¹Ÿéœ€è¦ Store (é•¿æœŸè·¨ä¼šè¯è®°å¿†)
checkpointer = MemorySaver()
in_memory_store = InMemoryStore()

app = workflow.compile(
    checkpointer=checkpointer,
    store=in_memory_store, 
)

# --- 8. æ¼”ç¤ºè¿è¡Œ ---

def run_long_context_demo():
    print("ğŸ§  å…·å¤‡é•¿çŸ­æœŸè®°å¿†ç®¡ç†çš„ Agent å·²å¯åŠ¨...")
    thread_id = "user_888" # æ¨¡æ‹ŸåŒä¸€ä¸ªç”¨æˆ·
    config = {"configurable": {"thread_id": thread_id}}
    
    # æ¨¡æ‹Ÿä¸€é•¿ä¸²å¯¹è¯ï¼Œè§‚å¯Ÿè®°å¿†çš„å˜åŒ–
    conversations = [
        "ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ã€‚",
        "æˆ‘æƒ³æŸ¥æŸ¥å»åŒ—äº¬çš„èˆªç­ã€‚", 
        "é‚£å»ä¸Šæµ·çš„å‘¢ï¼Ÿ",         
        "æˆ‘è§‰å¾— CA123 è¿˜å¯ä»¥ã€‚", # æ­¤æ—¶åº”è¯¥æ¥è¿‘è§¦å‘æ€»ç»“é˜ˆå€¼
        "å¯¹äº†ï¼Œæˆ‘æ¯”è¾ƒå–œæ¬¢é çª—çš„ä½ç½®ã€‚", # è§¦å‘æ€»ç»“ï¼Œå°†ä¹‹å‰çš„å¯¹è¯å‹ç¼©è¿› Store
        "å¸®æˆ‘é¢„è®¢ CA123ã€‚",         # Agent åº”è¯¥èƒ½ä» Store é‡Œæå–å‡ºæˆ‘æ˜¯å¼ ä¸‰
        "è°¢è°¢ï¼Œå†è§ã€‚"
    ]
    
    for i, user_input in enumerate(conversations):
        print(f"\n--- ç¬¬ {i+1} è½®å¯¹è¯ ---")
        print(f"ğŸ‘¤ User: {user_input}")
        
        input_msg = {"messages": [HumanMessage(content=user_input)]}
        
        # è¿è¡Œ
        for event in app.stream(input_msg, config=config):
            if "chatbot" in event:
                print(f"ğŸ¤– Agent: {event['chatbot']['messages'][-1].content}")
            if "tools" in event:
                print(f"ğŸ› ï¸ Tool: {event['tools']['messages'][-1].content}")
        
        # è°ƒè¯•ï¼šæŸ¥çœ‹å½“å‰ Checkpoint ä¸­çš„å®é™…æ¶ˆæ¯æ•°é‡ï¼ˆéªŒè¯ä¿®å‰ªæ˜¯å¦ç”Ÿæ•ˆï¼‰
        snapshot = app.get_state(config)
        msg_count = len(snapshot.values['messages'])
        print(f"ğŸ“Š å½“å‰ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°: {msg_count} (Store ä¸­æ˜¯å¦æœ‰è®°å¿†: æŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—)")

if __name__ == "__main__":
    run_long_context_demo()