import os
from typing import Annotated, Literal, TypedDict

from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import END, START, StateGraph, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition

# 1. å®šä¹‰å·¥å…· (Tools)
# è¿™é‡Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå¤©æ°”æŸ¥è¯¢å·¥å…·
@tool
def get_weather(city: str):
    """æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚"""
    # å®é™…åœºæ™¯ä¸­è¿™é‡Œå¯ä»¥è°ƒç”¨å¤–éƒ¨ API
    if "åŒ—äº¬" in city:
        return "åŒ—äº¬ä»Šå¤©æ˜¯æ™´å¤©ï¼Œæ°”æ¸© 25 åº¦ã€‚"
    elif "ä¸Šæµ·" in city:
        return "ä¸Šæµ·ä»Šå¤©æ˜¯é˜´å¤©ï¼Œæœ‰å°é›¨ï¼Œæ°”æ¸© 22 åº¦ã€‚"
    else:
        return f"æš‚æ—¶æ— æ³•è·å– {city} çš„å¤©æ°”æ•°æ®ã€‚"

tools = [get_weather]

# 2. åˆå§‹åŒ–æ¨¡å‹ (Model) å¹¶ç»‘å®šå·¥å…·
# åªæœ‰ç»‘å®šäº†å·¥å…·ï¼Œæ¨¡å‹æ‰çŸ¥é“å®ƒæœ‰èƒ½åŠ›è°ƒç”¨å‡½æ•°
llm = ChatOpenAI(model="Qwen3-30B-A3B", base_url="http://192.168.0.147:8997/v1", api_key="123456",temperature=0)
llm_with_tools = llm.bind_tools(tools)

# 3. å®šä¹‰å›¾çš„çŠ¶æ€ (State)
# LangGraph ä¸­çš„æ•°æ®æµè½¬æ˜¯åŸºäº State çš„ã€‚
# MessagesState æ˜¯å®˜æ–¹é¢„ç½®çš„åŒ…å« messages åˆ—è¡¨çš„ Stateï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ¶ˆæ¯è¿½åŠ 
class AgentState(MessagesState):
    # ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é¢å¤–çš„è‡ªå®šä¹‰çŠ¶æ€å­—æ®µ
    pass

# 4. å®šä¹‰èŠ‚ç‚¹ (Nodes)
# èŠ‚ç‚¹æ˜¯å›¾æ‰§è¡Œçš„å…·ä½“é€»è¾‘

def agent_node(state: AgentState):
    """
    Agent èŠ‚ç‚¹ï¼šè´Ÿè´£è°ƒç”¨å¤§æ¨¡å‹ï¼Œç”Ÿæˆå›å¤æˆ–å·¥å…·è°ƒç”¨è¯·æ±‚
    """
    messages = state["messages"]
    response = llm_with_tools.invoke(messages)
    # è¿”å›çš„å†…å®¹ä¼šé€šè¿‡ add_messages æœºåˆ¶è¿½åŠ åˆ° state["messages"] ä¸­
    return {"messages": [response]}

# 5. æ„å»ºå›¾ (Graph)
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("agent", agent_node)
# ToolNode æ˜¯ LangGraph é¢„ç½®çš„èŠ‚ç‚¹ï¼Œä¸“é—¨ç”¨äºæ‰§è¡Œå·¥å…·è°ƒç”¨
workflow.add_node("tools", ToolNode(tools))

# æ·»åŠ è¾¹ (Edges)
# å®šä¹‰æµç¨‹çš„å…¥å£
workflow.add_edge(START, "agent")

# å®šä¹‰æ¡ä»¶è¾¹ (Conditional Edges)
# ä» agent èŠ‚ç‚¹å‡ºæ¥åï¼Œå†³å®šä¸‹ä¸€æ­¥å»å“ªï¼š
# å¦‚æœæ¨¡å‹å†³å®šè°ƒç”¨å·¥å…· -> å» "tools" èŠ‚ç‚¹
# å¦‚æœæ¨¡å‹ç›´æ¥å›ç­” -> ç»“æŸ (END)
workflow.add_conditional_edges(
    "agent",
    tools_condition, # LangGraph é¢„ç½®çš„é€»è¾‘ï¼Œåˆ¤æ–­ message ä¸­æ˜¯å¦æœ‰ tool_calls
)

# å®šä¹‰æ™®é€šè¾¹
# å·¥å…·æ‰§è¡Œå®Œåï¼Œå¿…é¡»æŠŠç»“æœè¿”å›ç»™ agentï¼Œè®© agent ç»§ç»­æ€è€ƒ
workflow.add_edge("tools", "agent")

# 6. ç¼–è¯‘å›¾ (Compile)
# ç¼–è¯‘åç”Ÿæˆå¯æ‰§è¡Œçš„ Runnable
app = workflow.compile()

# --- å¯é€‰ï¼šç”Ÿæˆå›¾çš„ç»“æ„å›¾ (éœ€è¦å®‰è£… graphviz) ---
try:
    print(app.get_graph().draw_mermaid())
except:
    pass

# 7. è¿è¡Œ Demo
if __name__ == "__main__":
    print("Agent å·²å¯åŠ¨...")
    
    # æµ‹è¯•æ¡ˆä¾‹ 1ï¼šä¸éœ€è¦å·¥å…·
    print("\n--- æµ‹è¯• 1: æ™®é€šå¯¹è¯ ---")
    inputs = {"messages": [HumanMessage(content="ä½ å¥½ï¼Œè¯·åšä¸€ä¸ªè‡ªæˆ‘ä»‹ç»ã€‚")]}
    for chunk in app.stream(inputs, stream_mode="values"):
        message = chunk["messages"][-1]
        print(f"[{message.type}]: {message.content}")

    # æµ‹è¯•æ¡ˆä¾‹ 2ï¼šéœ€è¦è°ƒç”¨å·¥å…·
    print("\n--- æµ‹è¯• 2: å·¥å…·è°ƒç”¨ ---")
    inputs = {"messages": [HumanMessage(content="æˆéƒ½ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")]}
    # stream æ–¹æ³•ä¼šé€æ­¥è¾“å‡ºå›¾çš„æ‰§è¡ŒçŠ¶æ€
    for chunk in app.stream(inputs, stream_mode="values"):
        message = chunk["messages"][-1]
        
        if message.type == "ai":
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_calls = getattr(message, "tool_calls", [])
            if tool_calls:
                print(f"ğŸ¤– Agent å†³å®šè°ƒç”¨å·¥å…·: {tool_calls[0]['name']}")
            else:
                print(f"ğŸ¤– Agent å›å¤: {message.content}")
        elif message.type == "tool":
            print(f"ğŸ› ï¸ å·¥å…·è¿”å›ç»“æœ: {message.content}")